diff --git a/src/core/org/apache/hadoop/io/Text.java b/src/core/org/apache/hadoop/io/Text.java
index 19faa87..a058d22 100644
--- a/src/core/org/apache/hadoop/io/Text.java
+++ b/src/core/org/apache/hadoop/io/Text.java
@@ -21,6 +21,7 @@ package org.apache.hadoop.io;
 import java.io.IOException;
 import java.io.DataInput;
 import java.io.DataOutput;
+import java.io.InputStream;
 import java.nio.ByteBuffer;
 import java.nio.CharBuffer;
 import java.nio.charset.CharacterCodingException;
@@ -219,6 +220,30 @@ public class Text extends BinaryComparable
   }
 
   /**
+   * Append some bytes from inputstream to the end of the given text
+   * @param stream bytes source stream
+   * @param len the number of bytes to append
+   * @throws IOException
+   */
+  public void append(InputStream stream, int len) throws IOException {
+    setCapacity(length+len,  true);
+    stream.read(bytes, length, len);
+    length += len;
+  }
+
+  /**
+   * Append some bytes from ByteBuffer to the end of the given text
+   * @param buffer source ByteBuffer
+   * @param len the number of bytes to append
+   * @throws IOException
+   */
+  public void append(ByteBuffer buffer, int len) throws IOException {
+    setCapacity(length+len,  true);
+    buffer.get(bytes, length, len);
+    length += len;
+  }
+
+  /**
    * Clear the string to empty.
    */
   public void clear() {
diff --git a/src/mapred/org/apache/hadoop/mapred/MapTask.java b/src/mapred/org/apache/hadoop/mapred/MapTask.java
index 8a469ac..f403e9e 100644
--- a/src/mapred/org/apache/hadoop/mapred/MapTask.java
+++ b/src/mapred/org/apache/hadoop/mapred/MapTask.java
@@ -41,6 +41,7 @@ import java.util.concurrent.locks.ReentrantLock;
 import org.apache.commons.logging.Log;
 import org.apache.commons.logging.LogFactory;
 import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.filecache.TaskDistributedCacheManager;
 import org.apache.hadoop.fs.FSDataInputStream;
 import org.apache.hadoop.fs.FSDataOutputStream;
 import org.apache.hadoop.fs.FileSystem;
@@ -366,7 +367,15 @@ class MapTask extends Task {
       return;
     }
 
-    if (useNewApi) {
+    if (TaskDelegationUtil.canDelegateMapTask(job)) {
+      TaskDelegationUtil.delegateMapTask(
+          this,
+          job,
+          umbilical,
+          reporter,
+          getSplitDetails(new Path(splitMetaInfo.getSplitLocation()),
+                          splitMetaInfo.getStartOffset()));
+    } if (useNewApi) {
       runNewMapper(job, splitMetaInfo, umbilical, reporter);
     } else {
       runOldMapper(job, splitMetaInfo, umbilical, reporter);
@@ -425,7 +434,9 @@ class MapTask extends Task {
     LOG.info("numReduceTasks: " + numReduceTasks);
     MapOutputCollector collector = null;
     if (numReduceTasks > 0) {
-      collector = new MapOutputBuffer(umbilical, job, reporter);
+      collector = TaskDelegationUtil.tryGetDelegateMapOutputCollector(job, getTaskID(), mapOutputFile);
+      if (collector == null)
+        collector = new MapOutputBuffer(umbilical, job, reporter);
     } else { 
       collector = new DirectMapOutputCollector(umbilical, job, reporter);
     }
@@ -671,7 +682,8 @@ class MapTask extends Task {
                        TaskUmbilicalProtocol umbilical,
                        TaskReporter reporter
                        ) throws IOException, ClassNotFoundException {
-      collector = new MapOutputBuffer<K,V>(umbilical, job, reporter);
+      MapOutputCollector<K,V> tc = TaskDelegationUtil.tryGetDelegateMapOutputCollector(job, getTaskID(), mapOutputFile);
+      collector = tc != null ? tc : new MapOutputBuffer<K,V>(umbilical, job, reporter);
       partitions = jobContext.getNumReduceTasks();
       if (partitions > 0) {
         partitioner = (org.apache.hadoop.mapreduce.Partitioner<K,V>)
diff --git a/src/mapred/org/apache/hadoop/mapred/ReduceTask.java b/src/mapred/org/apache/hadoop/mapred/ReduceTask.java
index 980b988..a4b4777 100644
--- a/src/mapred/org/apache/hadoop/mapred/ReduceTask.java
+++ b/src/mapred/org/apache/hadoop/mapred/ReduceTask.java
@@ -413,7 +413,9 @@ class ReduceTask extends Task {
     Class valueClass = job.getMapOutputValueClass();
     RawComparator comparator = job.getOutputValueGroupingComparator();
 
-    if (useNewApi) {
+    if (TaskDelegationUtil.catDelegateReduceTask(job)) {
+      TaskDelegationUtil.delegateReduceTask(this, job, umbilical, reporter, rIter);
+    } else if (useNewApi) {
       runNewReducer(job, umbilical, reporter, rIter, comparator, 
                     keyClass, valueClass);
     } else {
diff --git a/src/mapred/org/apache/hadoop/mapred/TaskDelegationUtil.java b/src/mapred/org/apache/hadoop/mapred/TaskDelegationUtil.java
new file mode 100644
index 0000000..073c878
--- /dev/null
+++ b/src/mapred/org/apache/hadoop/mapred/TaskDelegationUtil.java
@@ -0,0 +1,117 @@
+/**
+ * Licensed to the Apache Software Foundation (ASF) under one
+ * or more contributor license agreements.  See the NOTICE file
+ * distributed with this work for additional information
+ * regarding copyright ownership.  The ASF licenses this file
+ * to you under the Apache License, Version 2.0 (the
+ * "License"); you may not use this file except in compliance
+ * with the License.  You may obtain a copy of the License at
+ *
+ *     http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+ * See the License for the specific language governing permissions and
+ * limitations under the License.
+ */
+
+package org.apache.hadoop.mapred;
+
+import java.io.IOException;
+import java.lang.reflect.Constructor;
+import java.lang.reflect.InvocationTargetException;
+import java.lang.reflect.Method;
+
+import org.apache.hadoop.io.BytesWritable;
+import org.apache.hadoop.io.DataInputBuffer;
+import org.apache.hadoop.mapred.Task.TaskReporter;
+import org.apache.hadoop.util.ReflectionUtils;
+
+public class TaskDelegationUtil {
+  public static boolean canDelegateMapTask(JobConf job) {
+    return job.get("mapreduce.map.task.delegator.class", null) != null;
+  }
+
+  public static void delegateMapTask(MapTask mapTask, JobConf job,
+      TaskUmbilicalProtocol umbilical, TaskReporter reporter,
+      Object split)
+      throws IOException, InterruptedException {
+    Class<?> delegatorClass = job.getClass("mapreduce.map.task.delegator.class", null);
+    Object delegator = ReflectionUtils.newInstance(delegatorClass, job);
+    try {
+      Method runMethod = delegatorClass.getMethod("run", TaskAttemptID.class,
+          JobConf.class, TaskUmbilicalProtocol.class, TaskReporter.class,
+          Object.class);
+      runMethod.invoke(delegator, mapTask.getTaskID(), job, umbilical, reporter,
+          split);
+    } catch (NoSuchMethodException e) {
+      throw new IOException(e);
+    } catch (IllegalAccessException e) {
+      throw new IOException(e);
+    } catch (InvocationTargetException e) {
+      Throwable orig = e.getTargetException();
+      if (orig instanceof IOException) {
+        throw (IOException)orig;
+      }
+      if (orig instanceof InterruptedException) {
+        throw (InterruptedException)orig;
+      }
+      throw new IOException(orig);
+    }
+  }
+
+  public static boolean catDelegateReduceTask(JobConf job) {
+    return job.get("mapreduce.reduce.task.delegator.class", null) != null;
+  }
+
+  public static void delegateReduceTask(ReduceTask reduceTask, JobConf job,
+      TaskUmbilicalProtocol umbilical, TaskReporter reporter,
+      RawKeyValueIterator rIter) throws IOException, ClassNotFoundException,
+      InterruptedException {
+    Class<?> delegatorClass = job.getClass("mapreduce.reduce.task.delegator.class", null);
+    Object delegator = ReflectionUtils.newInstance(delegatorClass, job);
+    try {
+      Method runMethod = delegatorClass.getMethod("run", TaskAttemptID.class,
+          JobConf.class, TaskUmbilicalProtocol.class, TaskReporter.class,
+          RawKeyValueIterator.class);
+      runMethod.invoke(delegator, reduceTask.getTaskID(), job, umbilical, reporter, rIter);
+    } catch (NoSuchMethodException e) {
+      throw new IOException(e);
+    } catch (IllegalAccessException e) {
+      throw new IOException(e);
+    } catch (InvocationTargetException e) {
+      Throwable orig = e.getTargetException();
+      if (orig instanceof IOException) {
+        throw (IOException)orig;
+      }
+      if (orig instanceof InterruptedException) {
+        throw (InterruptedException)orig;
+      }
+      throw new IOException(orig);
+    }
+  }
+
+
+  @SuppressWarnings("unchecked")
+  public static <K, V>
+  MapTask.MapOutputCollector<K, V> tryGetDelegateMapOutputCollector(
+      JobConf job, TaskAttemptID taskId, MapOutputFile mapOutputFile) {
+    try {
+      Class<?> cls = Class.forName(
+          "org.apache.hadoop.mapred.NativeMapOutputCollector");
+      Method canEnbaleMthd = cls.getMethod("canEnable", JobConf.class);
+      Boolean can = (Boolean)canEnbaleMthd.invoke(null, job);
+      if (can) {
+        Constructor<?> cons = cls.getConstructor(JobConf.class,
+            TaskAttemptID.class, MapOutputFile.class);
+        MapTask.MapOutputCollector<K,V> moc = (MapTask.MapOutputCollector<K,V>)
+            cons.newInstance(job, taskId, mapOutputFile);
+        return moc;
+      }
+      return null;
+    } catch (Exception e) {
+      return null;
+    }
+  }
+}
